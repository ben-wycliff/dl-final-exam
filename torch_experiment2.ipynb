{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1t2zuND2NTXHrAH-6p0uBRTG9au98L3hP",
      "authorship_tag": "ABX9TyNSPL+Czotm5KKc5JE0pYoo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ben-wycliff/dl-final-exam/blob/main/torch_experiment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-AxhSiBchUw",
        "outputId": "7b6f0725-bd66-4faf-cd38-34e9f9b127fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jxlcjkEAvDko"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"/content/drive/MyDrive/School/MSc Computer Science/Sem2 - (Ben Wycliff) - Year 1/Deep Learning/deep learning final exam/data.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "RsKXXS8XvgJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8XVvSGbNvdcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "xtjtZMWOvlMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to your dataset\n",
        "train_dir = 'data/train'\n",
        "test_dir = 'data/test'\n",
        "val_dir = 'data/val'\n",
        "\n",
        "# Set the input image dimensions\n",
        "input_shape = (256, 256)\n",
        "\n",
        "# Set the number of classes\n",
        "num_classes = 6\n",
        "\n",
        "# Define transformations for data normalization and grayscale conversion\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Grayscale(),\n",
        "    transforms.Resize(input_shape),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "\n",
        "# Create datasets for training, validation, and testing\n",
        "train_dataset = torchvision.datasets.ImageFolder(root=train_dir, transform=data_transforms)\n",
        "val_dataset = torchvision.datasets.ImageFolder(root=val_dir, transform=data_transforms)\n",
        "test_dataset = torchvision.datasets.ImageFolder(root=test_dir, transform=data_transforms)\n",
        "\n",
        "# Create data loaders for training, validation, and testing\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "TAgzBtORvjO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "aV0h2Kr1v1Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the convolutional neural network model\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32*32*128, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, num_classes),\n",
        "    nn.Softmax(dim=1)\n",
        ")"
      ],
      "metadata": {
        "id": "YcmSV7h_v098"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Move the model to the appropriate device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Set up TensorBoard writer\n",
        "log_dir = 'logs'\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "fHhIFGOuvz9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "-TSuLOuOwD-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_history = []\n",
        "train_acc_history = []\n",
        "valid_loss_history = []\n",
        "valid_acc_history = []\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "\n",
        "best_valid_acc = 0.0\n",
        "num_epochs = 40\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    train_running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update training loss and accuracy values\n",
        "        train_running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate training loss and accuracy for the epoch\n",
        "    train_epoch_loss = train_running_loss / len(train_loader)\n",
        "    train_epoch_acc = train_correct / train_total\n",
        "\n",
        "    # Append training loss and accuracy values to the history lists\n",
        "    train_loss_history.append(train_epoch_loss)\n",
        "    train_acc_history.append(train_epoch_acc)\n",
        "\n",
        "    # Validation step\n",
        "    model.eval()\n",
        "    valid_correct = 0\n",
        "    valid_total = 0\n",
        "    valid_running_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Update validation loss and accuracy values\n",
        "            valid_running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            valid_total += labels.size(0)\n",
        "            valid_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Calculate validation loss and accuracy for the epoch\n",
        "    valid_epoch_loss = valid_running_loss / len(val_loader)\n",
        "    valid_epoch_acc = valid_correct / valid_total\n",
        "\n",
        "    # Append validation loss and accuracy values to the history lists\n",
        "    valid_loss_history.append(valid_epoch_loss)\n",
        "    valid_acc_history.append(valid_epoch_acc)\n",
        "\n",
        "    # Print the loss and accuracy for each epoch\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
        "          f'Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_acc:.4f}, '\n",
        "          f'Valid Loss: {valid_epoch_loss:.4f}, Valid Acc: {valid_epoch_acc:.4f}')\n",
        "\n",
        "    # Check if the current model's validation accuracy is better than the previous best accuracy\n",
        "    if valid_epoch_acc > best_valid_acc:\n",
        "        best_valid_acc = valid_epoch_acc\n",
        "        best_model_weights = model.state_dict()\n",
        "\n",
        "print('Training finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34SGBnkhv9tE",
        "outputId": "c5c5db7f-79f5-4d22-b6e5-90b7495e7708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Train Loss: 1.6497, Train Acc: 0.3859, Valid Loss: 1.5486, Valid Acc: 0.4778\n",
            "Epoch [2/40], Train Loss: 1.5812, Train Acc: 0.4621, Valid Loss: 1.5511, Valid Acc: 0.4750\n",
            "Epoch [3/40], Train Loss: 1.5577, Train Acc: 0.4855, Valid Loss: 1.5788, Valid Acc: 0.4472\n",
            "Epoch [4/40], Train Loss: 1.5597, Train Acc: 0.4831, Valid Loss: 1.4932, Valid Acc: 0.5389\n",
            "Epoch [5/40], Train Loss: 1.5110, Train Acc: 0.5326, Valid Loss: 1.4610, Valid Acc: 0.5722\n",
            "Epoch [6/40], Train Loss: 1.5097, Train Acc: 0.5333, Valid Loss: 1.4602, Valid Acc: 0.5722\n",
            "Epoch [7/40], Train Loss: 1.4698, Train Acc: 0.5730, Valid Loss: 1.5168, Valid Acc: 0.5194\n",
            "Epoch [8/40], Train Loss: 1.4880, Train Acc: 0.5547, Valid Loss: 1.4306, Valid Acc: 0.6056\n",
            "Epoch [9/40], Train Loss: 1.4654, Train Acc: 0.5769, Valid Loss: 1.4363, Valid Acc: 0.5972\n",
            "Epoch [10/40], Train Loss: 1.4513, Train Acc: 0.5915, Valid Loss: 1.4282, Valid Acc: 0.6056\n",
            "Epoch [11/40], Train Loss: 1.4364, Train Acc: 0.6066, Valid Loss: 1.4012, Valid Acc: 0.6222\n",
            "Epoch [12/40], Train Loss: 1.4093, Train Acc: 0.6341, Valid Loss: 1.4054, Valid Acc: 0.6139\n",
            "Epoch [13/40], Train Loss: 1.3852, Train Acc: 0.6579, Valid Loss: 1.3612, Valid Acc: 0.6583\n",
            "Epoch [14/40], Train Loss: 1.3800, Train Acc: 0.6623, Valid Loss: 1.3932, Valid Acc: 0.6361\n",
            "Epoch [15/40], Train Loss: 1.3614, Train Acc: 0.6809, Valid Loss: 1.3716, Valid Acc: 0.6556\n",
            "Epoch [16/40], Train Loss: 1.3366, Train Acc: 0.7061, Valid Loss: 1.3445, Valid Acc: 0.6778\n",
            "Epoch [17/40], Train Loss: 1.3358, Train Acc: 0.7066, Valid Loss: 1.3411, Valid Acc: 0.6861\n",
            "Epoch [18/40], Train Loss: 1.3362, Train Acc: 0.7058, Valid Loss: 1.3421, Valid Acc: 0.6806\n",
            "Epoch [19/40], Train Loss: 1.3138, Train Acc: 0.7292, Valid Loss: 1.3369, Valid Acc: 0.6861\n",
            "Epoch [20/40], Train Loss: 1.3046, Train Acc: 0.7374, Valid Loss: 1.3160, Valid Acc: 0.7083\n",
            "Epoch [21/40], Train Loss: 1.3025, Train Acc: 0.7401, Valid Loss: 1.3232, Valid Acc: 0.7028\n",
            "Epoch [22/40], Train Loss: 1.2955, Train Acc: 0.7472, Valid Loss: 1.3359, Valid Acc: 0.6944\n",
            "Epoch [23/40], Train Loss: 1.2851, Train Acc: 0.7579, Valid Loss: 1.3114, Valid Acc: 0.7139\n",
            "Epoch [24/40], Train Loss: 1.2775, Train Acc: 0.7651, Valid Loss: 1.3277, Valid Acc: 0.7000\n",
            "Epoch [25/40], Train Loss: 1.2738, Train Acc: 0.7685, Valid Loss: 1.3089, Valid Acc: 0.7139\n",
            "Epoch [26/40], Train Loss: 1.2708, Train Acc: 0.7721, Valid Loss: 1.3176, Valid Acc: 0.7139\n",
            "Epoch [27/40], Train Loss: 1.2702, Train Acc: 0.7728, Valid Loss: 1.2972, Valid Acc: 0.7417\n",
            "Epoch [28/40], Train Loss: 1.2577, Train Acc: 0.7854, Valid Loss: 1.2851, Valid Acc: 0.7417\n",
            "Epoch [29/40], Train Loss: 1.2565, Train Acc: 0.7859, Valid Loss: 1.2984, Valid Acc: 0.7361\n",
            "Epoch [30/40], Train Loss: 1.2529, Train Acc: 0.7900, Valid Loss: 1.2912, Valid Acc: 0.7306\n",
            "Epoch [31/40], Train Loss: 1.2531, Train Acc: 0.7894, Valid Loss: 1.2741, Valid Acc: 0.7500\n",
            "Epoch [32/40], Train Loss: 1.2507, Train Acc: 0.7923, Valid Loss: 1.2677, Valid Acc: 0.7583\n",
            "Epoch [33/40], Train Loss: 1.2428, Train Acc: 0.8002, Valid Loss: 1.2520, Valid Acc: 0.7806\n",
            "Epoch [34/40], Train Loss: 1.2189, Train Acc: 0.8234, Valid Loss: 1.2513, Valid Acc: 0.7778\n",
            "Epoch [35/40], Train Loss: 1.1880, Train Acc: 0.8551, Valid Loss: 1.2667, Valid Acc: 0.7694\n",
            "Epoch [36/40], Train Loss: 1.1619, Train Acc: 0.8812, Valid Loss: 1.1955, Valid Acc: 0.8389\n",
            "Epoch [37/40], Train Loss: 1.1286, Train Acc: 0.9147, Valid Loss: 1.1819, Valid Acc: 0.8583\n",
            "Epoch [38/40], Train Loss: 1.1197, Train Acc: 0.9239, Valid Loss: 1.1735, Valid Acc: 0.8583\n",
            "Epoch [39/40], Train Loss: 1.1170, Train Acc: 0.9268, Valid Loss: 1.1719, Valid Acc: 0.8611\n",
            "Epoch [40/40], Train Loss: 1.1064, Train Acc: 0.9376, Valid Loss: 1.1611, Valid Acc: 0.8722\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "model.eval()\n",
        "val_predictions = []\n",
        "val_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        val_predictions.extend(predicted.cpu().numpy())\n",
        "        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert prediction labels and true labels to numpy arrays\n",
        "val_predictions = np.array(val_predictions)\n",
        "val_labels = np.array(val_labels)"
      ],
      "metadata": {
        "id": "jejf5WQuwGF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print classification report and confusion matrix\n",
        "print(\"Validation Classification Report:\")\n",
        "print(classification_report(val_labels, val_predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(val_labels, val_predictions))\n",
        "\n",
        "# Plot learning curves\n",
        "plt.plot(train_loss_history)\n",
        "plt.plot(valid_loss_history)\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xzNCLaSH0BOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curves\n",
        "plt.plot(train_acc_history)\n",
        "plt.plot(valid_acc_history)\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TZxRkQ9c0LsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-gFZ9GtWAiTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}